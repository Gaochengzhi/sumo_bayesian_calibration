{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Code \n",
    "## Convergence Comparison of Optimization Objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from task import SUMO_task, pbounds\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from multi_object_optimization import MooSUMOProblem, SinSUMOProblem\n",
    "import pandas as pd\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import itertools\n",
    "from util import json2pd\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['font.size'] = 15 \n",
    "plt.rcParams['font.family'] = ['Times New Roman','SimSun']\n",
    "plt.rcParams['font.weight'] = 'light'\n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "algo = [\"pso\", \"nsga3\", \"age2\"]\n",
    "SAVED_PATH = \"../output/plot/iteration\"\n",
    "\n",
    "\n",
    "def plot_object_f(env, algo_list, title=None):\n",
    "    markers = itertools.cycle(('^', 'x', 's', '*', 'h', 'H', 'D', 'd'))\n",
    "    marker_size = 6\n",
    "    line_styles = itertools.cycle((':', '--', '-.', '-'))\n",
    "    plt.figure(figsize=(4.0, 3.5))\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    min_points = []  # Store minimum value points for each algorithm\n",
    "    lines = []       # Store plot line objects for each algorithm to get colors\n",
    "\n",
    "    for algo in algo_list:\n",
    "        with open(f'../output/data_cache/{env}_{algo}.pkl', 'rb') as f:\n",
    "            res = pickle.load(f)\n",
    "            history = res.history\n",
    "            F_list = [entry.pop.get('F') for entry in history]\n",
    "            all_F = np.vstack(F_list)\n",
    "            df = pd.DataFrame(all_F, columns=[f'target{i}' for i in range(all_F.shape[1])])\n",
    "            df['mean_targets'] = df.mean(axis=1)\n",
    "            turning_points = df['mean_targets'].cummin()\n",
    "            \n",
    "            # Record minimum value point\n",
    "            min_idx = turning_points.idxmin()\n",
    "            min_val = turning_points.min()\n",
    "            min_points.append((min_idx, min_val, algo.upper()))\n",
    "\n",
    "            # Plot curve and store line object\n",
    "            line, = plt.plot(df.index, turning_points, label=f'{algo.upper()}', marker=next(markers), \n",
    "                             markersize=marker_size, markerfacecolor='none', \n",
    "                             markevery=[i for i in range(1, len(turning_points) - 1) \n",
    "                                        if turning_points[i] != turning_points[i - 1] \n",
    "                                        or turning_points[i] != turning_points[i + 1]], \n",
    "                             linewidth=0.8)\n",
    "            lines.append(line)\n",
    "\n",
    "    # Add Bayesian algorithm results\n",
    "    df = json2pd(f'../log/{env}.log')\n",
    "    df[\"cummax_target\"] = df[\"target\"].cummax()\n",
    "    bayesian_min_idx = (-df[\"cummax_target\"]).idxmin()\n",
    "    bayesian_min_val = (-df[\"cummax_target\"]).min()\n",
    "    min_points.append((bayesian_min_idx, bayesian_min_val, \"Bayesian\"))\n",
    "\n",
    "    bayesian_line, = plt.plot(df.index, -df[\"cummax_target\"], label=\"Bayesian\", marker=next(markers), \n",
    "                              markerfacecolor='none', \n",
    "                              markevery=[i for i in range(1, len(df[\"cummax_target\"]) - 1) \n",
    "                                         if df[\"cummax_target\"].iloc[i] != df[\"cummax_target\"].iloc[i - 1] \n",
    "                                         or df[\"cummax_target\"].iloc[i] != df[\"cummax_target\"].iloc[i + 1]], \n",
    "                              markersize=marker_size, linewidth=0.8)\n",
    "    lines.append(bayesian_line)\n",
    "\n",
    "    # Find global minimum point\n",
    "    global_min = min(min_points, key=lambda x: x[1])\n",
    "    \n",
    "    # Add annotations and arrows for each algorithm's minimum value\n",
    "    for i, (x, y, algo_name) in enumerate(min_points):\n",
    "        arrow_color = lines[i].get_color()  # Dynamically get the color of the corresponding curve\n",
    "        if (x, y) == (global_min[0], global_min[1]):  # Use different style for global minimum point\n",
    "            plt.annotate(f'{y:.3f}',\n",
    "                        xy=(x, y), xycoords='data',\n",
    "                        xytext=(-5, 70), textcoords='offset points',\n",
    "                        arrowprops=dict(arrowstyle=\"->\", color=arrow_color,shrinkB=25, lw=1.),  \n",
    "                        ha='center', va='bottom', fontweight='bold')\n",
    "        else:\n",
    "            plt.annotate(f'{y:.3f}',\n",
    "                        xy=(x, y), xycoords='data',\n",
    "                        xytext=(-5, 80), textcoords='offset points',\n",
    "                        arrowprops=dict(arrowstyle=\"->\", color=arrow_color, lw=1,shrinkB=25), \n",
    "                        ha='center', va='bottom')\n",
    "\n",
    "    plt.ylim(0.05, 0.6)\n",
    "    plt.xlim(-100, 3100)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(f'GoF Comparison in {title.upper()} Scenario')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Minimum KL Divergence')\n",
    "\n",
    "    plt.tight_layout(pad=1)\n",
    "    plt.grid(visible=True, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.savefig(f'{SAVED_PATH}/{env}_comparison.pdf', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_object_f(\"merge\", algo, \"MERGE\")\n",
    "plot_object_f(\"right\", algo, \"NARROW\")\n",
    "plot_object_f(\"stop\", algo, \"STOP\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Convergence Performance of Different Algorithms in Various Scenarios $\\LaTeX$ Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from util import json2pd\n",
    "import os\n",
    "\n",
    "def load_and_analyze_data_extended(env_list, algo_list):\n",
    "    \"\"\"\n",
    "    Load and analyze the convergence performance of different algorithms in various scenarios, including extended statistics.\n",
    "    \n",
    "    Args:\n",
    "    env_list: List of scenarios, e.g., [\"merge\", \"right\", \"stop\"]\n",
    "    algo_list: List of algorithms, e.g., [\"pso\", \"nsga3\", \"age2\"]\n",
    "    \n",
    "    Returns:\n",
    "    results_df: DataFrame containing the convergence performance of each algorithm in each scenario\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    env_name_map = {\n",
    "        \"merge\": \"Merge\",\n",
    "        \"right\": \"Narrow Road\",\n",
    "        \"stop\": \"Stop and Give Way\"\n",
    "    }\n",
    "    \n",
    "    for env in env_list:\n",
    "        try:\n",
    "            bayesian_df = json2pd(f'../log/{env}.log')\n",
    "            bayesian_df[\"cummax_target\"] = bayesian_df[\"target\"].cummax()\n",
    "            bayesian_min_idx = (-bayesian_df[\"cummax_target\"]).idxmin()\n",
    "            bayesian_min_val = -bayesian_df[\"cummax_target\"].min()\n",
    "            bayesian_iterations = len(bayesian_df)\n",
    "            initial_kl = -bayesian_df[\"cummax_target\"].iloc[0]\n",
    "            \n",
    "            # 1. Convergence rate\n",
    "            convergence_rate = (initial_kl - bayesian_min_val) / max(1, bayesian_min_idx)\n",
    "            \n",
    "            # 2. Stability metric (std of last 100 iterations)\n",
    "            if len(bayesian_df) > 100:\n",
    "                stability = bayesian_df[\"cummax_target\"].iloc[-100:].std()\n",
    "            else:\n",
    "                stability = bayesian_df[\"cummax_target\"].std()\n",
    "            \n",
    "            # 3. Initial convergence speed (first 100 iterations)\n",
    "            early_iterations = min(100, len(bayesian_df))\n",
    "            if early_iterations > 1:\n",
    "                early_values = -bayesian_df[\"cummax_target\"].iloc[:early_iterations]\n",
    "                early_convergence = (early_values.iloc[0] - early_values.iloc[-1]) / early_iterations\n",
    "            else:\n",
    "                early_convergence = 0\n",
    "            \n",
    "            # 4. Relative improvement rate\n",
    "            if initial_kl > 0:\n",
    "                relative_improvement = (initial_kl - bayesian_min_val) / initial_kl * 100\n",
    "            else:\n",
    "                relative_improvement = 0\n",
    "            \n",
    "            results.append({\n",
    "                \"Scenario\": env_name_map.get(env, env),\n",
    "                \"Algorithm\": \"Bayesian\",\n",
    "                \"Min KL Divergence\": bayesian_min_val,\n",
    "                \"Convergence Iterations\": bayesian_min_idx,\n",
    "                \"Total Iterations\": bayesian_iterations,\n",
    "                \"Convergence Efficiency\": bayesian_min_idx / bayesian_iterations,\n",
    "                \"Convergence Rate\": convergence_rate,\n",
    "                \"Stability Metric\": stability,\n",
    "                \"Initial Convergence Speed\": early_convergence,\n",
    "                \"Relative Improvement (%)\": relative_improvement\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load Bayesian algorithm data in {env} scenario: {e}\")\n",
    "        \n",
    "        # Process other algorithms\n",
    "        for algo in algo_list:\n",
    "            try:\n",
    "                with open(f'../output/data_cache/{env}_{algo}.pkl', 'rb') as f:\n",
    "                    res = pickle.load(f)\n",
    "                    history = res.history\n",
    "                    F_list = [entry.pop.get('F') for entry in history]\n",
    "                    all_F = np.vstack(F_list)\n",
    "                    df = pd.DataFrame(all_F, columns=[f'target{i}' for i in range(all_F.shape[1])])\n",
    "                    df['mean_targets'] = df.mean(axis=1)\n",
    "                    turning_points = df['mean_targets'].cummin()\n",
    "                    \n",
    "                    # Basic metrics\n",
    "                    min_idx = turning_points.idxmin()\n",
    "                    min_val = turning_points.min()\n",
    "                    total_iterations = len(turning_points)\n",
    "                    initial_kl = turning_points.iloc[0]\n",
    "                    \n",
    "                    # Extended metrics\n",
    "                    # 1. Convergence rate\n",
    "                    convergence_rate = (initial_kl - min_val) / max(1, min_idx)\n",
    "                    \n",
    "                    # 2. Stability metric (std of last 100 iterations)\n",
    "                    if len(turning_points) > 100:\n",
    "                        stability = turning_points.iloc[-100:].std()\n",
    "                    else:\n",
    "                        stability = turning_points.std()\n",
    "                    \n",
    "                    # 3. Initial convergence speed (first 100 iterations)\n",
    "                    early_iterations = min(100, len(turning_points))\n",
    "                    if early_iterations > 1:\n",
    "                        early_values = turning_points.iloc[:early_iterations]\n",
    "                        early_convergence = (early_values.iloc[0] - early_values.iloc[-1]) / early_iterations\n",
    "                    else:\n",
    "                        early_convergence = 0\n",
    "                    \n",
    "                    # 4. Relative improvement rate\n",
    "                    if initial_kl > 0:\n",
    "                        relative_improvement = (initial_kl - min_val) / initial_kl * 100\n",
    "                    else:\n",
    "                        relative_improvement = 0\n",
    "                    \n",
    "                    results.append({\n",
    "                        \"Scenario\": env_name_map.get(env, env),\n",
    "                        \"Algorithm\": algo.upper(),\n",
    "                        \"Min KL Divergence\": min_val,\n",
    "                        \"Convergence Iterations\": min_idx,\n",
    "                        \"Total Iterations\": total_iterations,\n",
    "                        \"Convergence Efficiency\": min_idx / total_iterations,\n",
    "                        \"Convergence Rate\": convergence_rate,\n",
    "                        \"Stability Metric\": stability,\n",
    "                        \"Initial Convergence Speed\": early_convergence,\n",
    "                        \"Relative Improvement (%)\": relative_improvement\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {algo} algorithm data in {env} scenario: {e}\")\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "def generate_extended_latex_table(results_df, selected_metrics):\n",
    "    \"\"\"\n",
    "    Generate a LaTeX three-line table with extended statistics.\n",
    "    \n",
    "    Args:\n",
    "    results_df: DataFrame containing results\n",
    "    selected_metrics: List of metrics to include in the table\n",
    "    \n",
    "    Returns:\n",
    "    latex_code: LaTeX table code\n",
    "    \"\"\"\n",
    "    # Sort and process data\n",
    "    results_df = results_df.sort_values(by=[\"Scenario\", \"Min KL Divergence\"])\n",
    "    \n",
    "    # Mark the best algorithm for each scenario\n",
    "    best_per_scene = results_df.groupby(\"Scenario\")[\"Min KL Divergence\"].idxmin()\n",
    "    results_df[\"Is Best\"] = False\n",
    "    results_df.loc[best_per_scene, \"Is Best\"] = True\n",
    "    \n",
    "    # Format values\n",
    "    format_dict = {\n",
    "        \"Min KL Divergence\": lambda x: f\"{x:.4f}\",\n",
    "        \"Convergence Iterations\": lambda x: f\"{int(x)}\",\n",
    "        \"Total Iterations\": lambda x: f\"{int(x)}\",\n",
    "        \"Convergence Efficiency\": lambda x: f\"{x:.2f}\",\n",
    "        \"Convergence Rate\": lambda x: f\"{x:.5f}\",\n",
    "        \"Stability Metric\": lambda x: f\"{x:.5f}\",\n",
    "        \"Initial Convergence Speed\": lambda x: f\"{x:.5f}\",\n",
    "        \"Relative Improvement (%)\": lambda x: f\"{x:.1f}\"\n",
    "    }\n",
    "    \n",
    "    for metric in selected_metrics:\n",
    "        if metric in format_dict:\n",
    "            results_df[metric] = results_df[metric].apply(format_dict[metric])\n",
    "    \n",
    "    # Generate table header\n",
    "    column_count = len(selected_metrics) + 2  # +2 for Scenario and Algorithm\n",
    "    tabular_format = \"c\" * column_count\n",
    "    \n",
    "    latex_code = f\"\"\"\n",
    "\\\\begin{{table}}[h]\n",
    "    \\\\centering\n",
    "    \\\\renewcommand{{\\\\arraystretch}}{{1.5}}\n",
    "    \\\\setlength{{\\\\tabcolsep}}{{8pt}} % Adjust column width\n",
    "    \\\\bicaption{{Convergence Performance Comparison of Different Algorithms in Various Scenarios}}{{Convergence Performance Comparison of Different Algorithms in Various Scenarios}}\n",
    "    \\\\label{{tab:convergence_comparison_extended}}\n",
    "    \\\\begin{{tabular}}{{{tabular_format}}}\n",
    "    \\\\toprule[1.5pt]\n",
    "    Scenario & Algorithm\"\"\"\n",
    "    \n",
    "    # Add metric names to header\n",
    "    for metric in selected_metrics:\n",
    "        latex_code += f\" & {metric}\"\n",
    "    \n",
    "    latex_code += \" \\\\\\\\\\n    \\\\midrule[0.75pt]\\n\"\n",
    "    \n",
    "    current_scene = None\n",
    "    scene_count = 0\n",
    "    \n",
    "    for _, row in results_df.iterrows():\n",
    "        if current_scene != row[\"Scenario\"]:\n",
    "            if current_scene is not None:\n",
    "                latex_code += r\"    \\midrule[0.75pt]\" + \"\\n\"\n",
    "            current_scene = row[\"Scenario\"]\n",
    "            scene_count = 0\n",
    "        \n",
    "        # Bold the best algorithm\n",
    "        if row[\"Is Best\"]:\n",
    "            algo_str = r\"\\textbf{\" + row[\"Algorithm\"] + r\"}\"\n",
    "        else:\n",
    "            algo_str = row[\"Algorithm\"]\n",
    "        \n",
    "        # Use multirow to merge scenario cells\n",
    "        if scene_count == 0:\n",
    "            scene_cell = r\"\\multirow{4}{*}{\" + row['Scenario'] + r\"}\"\n",
    "        else:\n",
    "            scene_cell = \"\"\n",
    "        \n",
    "        latex_code += f\"    {scene_cell} & {algo_str}\"\n",
    "        \n",
    "        for metric in selected_metrics:\n",
    "            value = row[metric]\n",
    "            if metric == \"Min KL Divergence\" and row[\"Is Best\"]:\n",
    "                value = r\"\\textbf{\" + value + r\"}\"\n",
    "            latex_code += f\" & {value}\"\n",
    "        \n",
    "        latex_code += \" \\\\\\\\\\n\"\n",
    "        scene_count += 1\n",
    "    \n",
    "    latex_code += r\"\"\"    \\bottomrule[1.5pt]  \n",
    "    \\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    return latex_code\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    env_list = [\"merge\", \"right\", \"stop\"]\n",
    "    algo_list = [\"pso\", \"nsga3\", \"age2\"]\n",
    "    \n",
    "    # Analyze overall convergence performance of algorithms, including extended statistics\n",
    "    print(\"Loading data...\")\n",
    "    results_df = load_and_analyze_data_extended(env_list, algo_list)\n",
    "    \n",
    "    # Generate tables for different metric combinations\n",
    "    # Table 1: Basic metrics\n",
    "    basic_metrics = [\"Min KL Divergence\", \"Convergence Iterations\", \"Convergence Efficiency\"]\n",
    "    latex_table_basic = generate_extended_latex_table(results_df, basic_metrics)\n",
    "    \n",
    "    # Table 2: Convergence speed related metrics\n",
    "    speed_metrics = [\"Min KL Divergence\", \"Convergence Rate\", \"Initial Convergence Speed\"]\n",
    "    latex_table_speed = generate_extended_latex_table(results_df, speed_metrics)\n",
    "    \n",
    "    # Table 3: Stability and improvement rate\n",
    "    stability_metrics = [\"Min KL Divergence\", \"Stability Metric\", \"Relative Improvement (%)\"]\n",
    "    latex_table_stability = generate_extended_latex_table(results_df, stability_metrics)\n",
    "    \n",
    "    # Table 4: Comprehensive metrics\n",
    "    comprehensive_metrics = [\"Min KL Divergence\", \"Convergence Iterations\", \"Initial Convergence Speed\", \"Convergence Efficiency\"]\n",
    "    latex_table_comprehensive = generate_extended_latex_table(results_df, comprehensive_metrics)\n",
    "    \n",
    "    return latex_table_basic, latex_table_speed, latex_table_stability, latex_table_comprehensive\n",
    "\n",
    "# Run main function\n",
    "if __name__ == \"__main__\":\n",
    "    latex_table_basic, latex_table_speed, latex_table_stability, latex_table_comprehensive = main()\n",
    "    print(latex_table_comprehensive)\n",
    "    print(\"LaTeX table generated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Convergence Speed for Multi-objective Algorithm Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from task import SUMO_task, pbounds  \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from multi_object_optimization import MooSUMOProblem, SinSUMOProblem  # Assume these modules exist and are available\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "plt.rcParams['font.size'] = 15\n",
    "plt.rcParams[\"font.family\"] = [\"Times New Roman\", \"SimSun\"]\n",
    "plt.rcParams[\"font.serif\"] = [\"Times New Roman\", \"SimSun\"]\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Times New Roman\", \"SimSun\"]\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"custom\"\n",
    "\n",
    "SAVED_PATH = \"../output/plot/iteration\"\n",
    "\n",
    "\n",
    "def plot_object_f(env, algo):\n",
    "    # English label mapping\n",
    "    name_map = {\n",
    "        'Car acc': 'Car Acceleration',\n",
    "        'Car dhw': 'Car Headway',\n",
    "        'Car v': 'Car Speed',\n",
    "        'Bus acc': 'Bus Acceleration',\n",
    "        'Bus dhw': 'Bus Headway',\n",
    "        'Bus v': 'Bus Speed'\n",
    "    }\n",
    "\n",
    "    markers = itertools.cycle(('^', 'x', 's', '*', 'h', 'H', 'D', 'd'))\n",
    "    marker_size = 6\n",
    "    line_styles = itertools.cycle((':', '--', '-.', '-'))\n",
    "    plt.figure(figsize=(7.5, 6))  # Adjust figure size\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    try:\n",
    "        with open(f'../output/data_cache/{env}_{algo}.pkl', 'rb') as f:\n",
    "            res = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: ../output/data_cache/{env}_{algo}.pkl\")\n",
    "        return\n",
    "    \n",
    "    history = res.history\n",
    "    F_list = [entry.pop.get('F') for entry in history]\n",
    "    all_F = np.vstack(F_list)\n",
    "    target_names = ['Car acc', 'Car dhw', 'Car v', 'Bus acc', 'Bus dhw', 'Bus v']\n",
    "    df = pd.DataFrame(all_F, columns=target_names)\n",
    "\n",
    "    lines = []  # Store line objects for later color retrieval\n",
    "    min_points = []  # Store the coordinates and labels of the minimum value for each metric\n",
    "\n",
    "    for target in target_names:\n",
    "        turning_points = df[target].cummin()\n",
    "        line, = plt.plot(df.index, turning_points, label=name_map.get(target, target),\n",
    "                         marker=next(markers),\n",
    "                         markersize=marker_size,\n",
    "                         markerfacecolor='none',\n",
    "                         markevery=[i for i in range(1, len(turning_points) - 1)\n",
    "                                    if turning_points[i] != turning_points[i - 1]\n",
    "                                    or turning_points[i] != turning_points[i + 1]],\n",
    "                         linewidth=0.8)\n",
    "        lines.append(line)\n",
    "\n",
    "        # Find the minimum value point and add it to the min_points list\n",
    "        min_idx = turning_points.idxmin()\n",
    "        min_val = turning_points.min()\n",
    "        min_points.append((min_idx, min_val, name_map.get(target, target)))\n",
    "\n",
    "    global_min = min(min_points, key=lambda x: x[1])\n",
    "\n",
    "    # Add annotations and arrows\n",
    "    for i, (x, y, label) in enumerate(min_points):\n",
    "        arrow_color = lines[i].get_color() # Get the color of the corresponding curve\n",
    "\n",
    "        hight = [30,40,60,80,100, 120]\n",
    "        if (x, y) == (global_min[0], global_min[1]):\n",
    "            plt.annotate(f'{y:.3f}',\n",
    "                        xy=(x, y), xycoords='data',\n",
    "                        xytext=(-15,hight[i]), textcoords='offset points',  # Adjust annotation position\n",
    "                        arrowprops=dict(arrowstyle=\"->\", color=arrow_color, lw=1, shrinkB=15),\n",
    "                        ha='center', va='bottom', fontweight='bold')\n",
    "        else:\n",
    "            plt.annotate(f'{y:.3f}',\n",
    "                        xy=(x, y), xycoords='data',\n",
    "                        xytext=(-15,hight[i]), textcoords='offset points',  # Adjust annotation position\n",
    "                        arrowprops=dict(arrowstyle=\"->\", color=arrow_color, lw=1, shrinkB=15),\n",
    "                        ha='center', va='bottom')\n",
    "\n",
    "    plt.ylim(-0.05, 1)  # Adjust y-axis\n",
    "    plt.xlim(-100, 3100)\n",
    "    plt.legend(loc='upper right',fontsize=13,ncol=2)  # Add legend\n",
    "\n",
    "    # Set title according to environment\n",
    "    title_map = {\n",
    "        \"merge\": \"MERGE\",\n",
    "        \"stop\": \"STOP\",\n",
    "        \"right\": \"RIGHT\"\n",
    "    }\n",
    "    title_en = title_map.get(env, env.upper())  # Get English title, use uppercase if not found\n",
    "\n",
    "    plt.title(f'MoP Comparison for {algo.upper()} in {title_en} Scenario')  # Use English title\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Minimum KL Divergence')\n",
    "\n",
    "    plt.tight_layout(pad=2)  # Adjust layout\n",
    "    plt.grid(visible=True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    plt.savefig(f'{SAVED_PATH}/{env}_{algo}_object_f.pdf', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "algo_list = [\"nsga3\", \"age2\"]\n",
    "envs = [\"merge\", \"stop\", \"right\"]\n",
    "for env in envs:\n",
    "    for algo in algo_list:\n",
    "        plot_object_f(env, algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Minimum KL Divergence Values for Each Performance Metric under Different Scenarios and Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def extract_data_and_generate_latex():\n",
    "    envs = [\"merge\", \"stop\", \"right\"]\n",
    "    algo_list = [\"nsga3\", \"age2\"]\n",
    "    \n",
    "    # Chinese label mapping\n",
    "    name_map = {\n",
    "        'Car acc': 'Car Acceleration',\n",
    "        'Car dhw': 'Car Headway',\n",
    "        'Car v': 'Car Velocity',\n",
    "        'Bus acc': 'Bus Acceleration',\n",
    "        'Bus dhw': 'Bus Headway',\n",
    "        'Bus v': 'Bus Velocity'\n",
    "    }\n",
    "    \n",
    "    # English label mapping\n",
    "    eng_map = {\n",
    "        'Car acc': 'Car Acceleration',\n",
    "        'Car dhw': 'Car Headway',\n",
    "        'Car v': 'Car Velocity',\n",
    "        'Bus acc': 'Bus Acceleration',\n",
    "        'Bus dhw': 'Bus Headway',\n",
    "        'Bus v': 'Bus Velocity'\n",
    "    }\n",
    "    \n",
    "    # Scenario mapping\n",
    "    env_map = {\n",
    "        \"merge\": \"MERGE\",\n",
    "        \"stop\": \"STOP\",\n",
    "        \"right\": \"NARROW\"\n",
    "    }\n",
    "    \n",
    "    # Algorithm mapping\n",
    "    algo_map = {\n",
    "        \"nsga3\": \"NSGA-III\",\n",
    "        \"age2\": \"AGE-II\"\n",
    "    }\n",
    "    \n",
    "    # Create result storage structure\n",
    "    results = {}\n",
    "    target_names = ['Car acc', 'Car dhw', 'Car v', 'Bus acc', 'Bus dhw', 'Bus v']\n",
    "    \n",
    "    # Extract data\n",
    "    for env in envs:\n",
    "        results[env] = {}\n",
    "        for algo in algo_list:\n",
    "            try:\n",
    "                with open(f'../output/data_cache/{env}_{algo}.pkl', 'rb') as f:\n",
    "                    res = pickle.load(f)\n",
    "                    \n",
    "                history = res.history\n",
    "                F_list = [entry.pop.get('F') for entry in history]\n",
    "                all_F = np.vstack(F_list)\n",
    "                df = pd.DataFrame(all_F, columns=target_names)\n",
    "                \n",
    "                # Calculate the minimum value for each metric\n",
    "                min_values = {}\n",
    "                for target in target_names:\n",
    "                    turning_points = df[target].cummin()\n",
    "                    min_val = turning_points.min()\n",
    "                    min_values[target] = min_val\n",
    "                \n",
    "                results[env][algo] = min_values\n",
    "                \n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found: ../output/data_cache/{env}_{algo}.pkl\")\n",
    "                results[env][algo] = {target: \"N/A\" for target in target_names}\n",
    "    \n",
    "    # Find the global minimum for each metric\n",
    "    global_min = {}\n",
    "    for target in target_names:\n",
    "        min_val = float('inf')\n",
    "        for env in envs:\n",
    "            for algo in algo_list:\n",
    "                if isinstance(results[env][algo][target], (int, float)) and results[env][algo][target] < min_val:\n",
    "                    min_val = results[env][algo][target]\n",
    "        global_min[target] = min_val\n",
    "    \n",
    "    # Generate LaTeX table\n",
    "    latex_code = r'''\\begin{table}[h]\n",
    "    \\centering\n",
    "    \\renewcommand{\\arraystretch}{1.5}\n",
    "    \\setlength{\\tabcolsep}{10pt} % Adjust column width\n",
    "    \\bicaption{Minimum KL Divergence Values for Different Scenarios and Algorithms}{Minimum KL Divergence Values for Different Scenarios and Algorithms}\n",
    "    \\label{tab:kl_divergence}\n",
    "    \\begin{tabular}{ccccccccc}\n",
    "    \\toprule[1.5pt]\n",
    "    \\multirow{2}{*}{Scenario} & \\multirow{2}{*}{Algorithm} & \\multicolumn{3}{c}{Car} & \\multicolumn{3}{c}{Bus} \\\\\n",
    "    \\cmidrule(lr){3-5} \\cmidrule(lr){6-8}\n",
    "    & & Acceleration & Headway & Velocity & Acceleration & Headway & Velocity \\\\\n",
    "    \\midrule[0.75pt]'''\n",
    "    \n",
    "    # Add data rows\n",
    "    for env in envs:\n",
    "        for i, algo in enumerate(algo_list):\n",
    "            if i == 0:\n",
    "                row = f\"\\n    \\\\multirow{{2}}{{*}}{{{env_map[env]}}} & {algo_map[algo]}\"\n",
    "            else:\n",
    "                row = f\"\\n    & {algo_map[algo]}\"\n",
    "                \n",
    "            for target in ['Car acc', 'Car dhw', 'Car v', 'Bus acc', 'Bus dhw', 'Bus v']:\n",
    "                if isinstance(results[env][algo][target], (int, float)):\n",
    "                    # Bold if it is the minimum value\n",
    "                    if abs(results[env][algo][target] - global_min[target]) < 1e-6:  # Use small epsilon for float comparison\n",
    "                        row += f\" & \\\\textbf{{{results[env][algo][target]:.3f}}}\"\n",
    "                    else:\n",
    "                        row += f\" & {results[env][algo][target]:.3f}\"\n",
    "                else:\n",
    "                    row += f\" & {results[env][algo][target]}\"\n",
    "            \n",
    "            latex_code += row + \" \\\\\\\\\"\n",
    "            \n",
    "        if env != envs[-1]:\n",
    "            latex_code += \"\\n    \\\\midrule\"\n",
    "    \n",
    "    # Finish table\n",
    "    latex_code += r'''\n",
    "    \\bottomrule[1.5pt]  \n",
    "    \\end{tabular}\n",
    "\\end{table}'''\n",
    "    \n",
    "    return latex_code\n",
    "\n",
    "# Run the function and print the result\n",
    "latex_table = extract_data_and_generate_latex()\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Distributions: Calibrated Parameters, Real Data, and Uncalibrated SUMO Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of Distributions: Calibrated Parameters, Real Data, and Uncalibrated SUMO Parameters\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "plt.rcParams[\"font.family\"] = [\"Times New Roman\", \"SimSun\"]\n",
    "plt.rcParams[\"font.serif\"] = [\"Times New Roman\", \"SimSun\"]\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Times New Roman\", \"SimSun\"]\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"stix\"\n",
    "plt.rcParams[\"mathtext.rm\"] = \"SimSun\"\n",
    "SAVED_PATH = \"../output/plot/distribution\"\n",
    "\n",
    "# Vehicle type mapping\n",
    "vehicle_type_map = {\n",
    "    \"bus\": \"Bus\",\n",
    "    \"car\": \"Car\"\n",
    "}\n",
    "\n",
    "# Variable name mapping\n",
    "name_map = {\n",
    "    \"velocity\": \"Velocity\",\n",
    "    \"acceleration\": \"Acceleration\",\n",
    "    \"time headway\": \"Time Headway\"\n",
    "}\n",
    "\n",
    "def plot_distribution_comparison(data_list, vehicle_type, variable, output_dir, index):\n",
    "    \"\"\"\n",
    "    Plot distribution comparison (histogram + kernel density estimation)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(3.6, 3))\n",
    "    colors = [\"#5b9bd5\", \"#ed7d31\", \"#70ad47\"]\n",
    "    labels = [\"Calibrated\", \"Ground Truth\", \"SUMO\"]\n",
    "\n",
    "    for idx, (data, color) in enumerate(zip(data_list, colors)):\n",
    "        hist_data, bin_width, bin_centers, kde_x, kde_y = data\n",
    "        plt.bar(\n",
    "            bin_centers,\n",
    "            height=hist_data,\n",
    "            width=bin_width,\n",
    "            align=\"center\",\n",
    "            edgecolor=\"k\",\n",
    "            alpha=0.39,\n",
    "            color=color,\n",
    "            linewidth=0.3,\n",
    "            label=f\"{labels[idx]}\",\n",
    "        )\n",
    "        plt.plot(kde_x, kde_y, color=color, linestyle=\"-\", linewidth=0.5)\n",
    "\n",
    "    if len(data_list) > 1:\n",
    "        _, _, _, kde_x_second, _ = data_list[1]\n",
    "        plt.xlim(min(kde_x_second), max(kde_x_second))\n",
    "\n",
    "    subplot_label = f\"({chr(97 + index)})\"\n",
    "    plt.text(-0.1, 1.03, subplot_label, transform=plt.gca().transAxes, fontsize=12)\n",
    "\n",
    "    font_size = 12\n",
    "\n",
    "    vehicle_type_en = vehicle_type_map.get(vehicle_type.lower(), vehicle_type)\n",
    "\n",
    "    if variable == \"xVelocity\":\n",
    "        plt.xlabel(f\"Velocity $(m/s)$\", fontsize=font_size, labelpad=1)\n",
    "        variable_en = name_map.get(\"velocity\", \"Velocity\")\n",
    "    elif variable == \"xAcceleration\":\n",
    "        plt.xlabel(f\"Acceleration $(m/s^2)$\", fontsize=font_size, labelpad=1)\n",
    "        variable_en = name_map.get(\"acceleration\", \"Acceleration\")\n",
    "    elif variable == \"dhw\":\n",
    "        plt.xlabel(f\"Time Headway $(m)$\", fontsize=font_size, labelpad=1)\n",
    "        variable_en = name_map.get(\"time headway\", \"Time Headway\")\n",
    "    else:\n",
    "        variable_en = variable\n",
    "\n",
    "    plt.title(f\"{vehicle_type_en} {variable_en} Distribution\", fontsize=font_size)\n",
    "    plt.legend(loc=\"upper right\", fontsize=12)\n",
    "    plt.xticks(fontsize=font_size)\n",
    "    plt.yticks(fontsize=font_size)\n",
    "    plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    plt.grid(visible=True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout(pad=0.2)\n",
    "\n",
    "    output_file = os.path.join(\n",
    "        output_dir, f\"{env}_{vehicle_type}_{variable}_distribution.pdf\"\n",
    "    )\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()\n",
    "\n",
    "def batch_plot_distribution_comparison(caches, output_dir, start_index=0):\n",
    "    \"\"\"\n",
    "    Batch plot distribution comparisons from cache files\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for cache in caches:\n",
    "        with open(cache, \"rb\") as f:\n",
    "            dfs.append(pickle.load(f))\n",
    "\n",
    "    hist_kde_data = [df[\"hist_kde_data\"] for df in dfs]\n",
    "\n",
    "    keys = set(hist_kde_data[0].keys())\n",
    "    for data in hist_kde_data[1:]:\n",
    "        keys.intersection_update(data.keys())\n",
    "\n",
    "    idx = start_index\n",
    "    for cache_key in sorted(list(keys)):\n",
    "        vehicle_type, variable = cache_key.split(\"_\")\n",
    "        data_list = [data[cache_key] for data in hist_kde_data]\n",
    "        plot_distribution_comparison(data_list, vehicle_type, variable, output_dir, idx)\n",
    "        idx += 1\n",
    "    return idx\n",
    "\n",
    "current_index = 0\n",
    "for env in [\"merge\", \"right\", \"stop\"]:\n",
    "    current_index = batch_plot_distribution_comparison([\n",
    "        f\"../output/data_raw/{env}/_cache.pkl\",\n",
    "        f\"../output/data_cache/{env}_cache.pkl\",\n",
    "        f\"../output/data_raw/{env}_origin/_cache.pkl\"\n",
    "    ], SAVED_PATH, current_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pareto Front Distribution Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pareto Front Distribution Plot (English Version)\n",
    "\n",
    "from multi_object_optimization import MooSUMOProblem, SinSUMOProblem\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Font settings for English and Chinese\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.rcParams['font.family'] = ['Times New Roman', 'SimSun']\n",
    "plt.rcParams['font.weight'] = 'light'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# List of environments and algorithms\n",
    "environments = [\"merge\", \"stop\", \"right\"]\n",
    "algorithms = [\"age2\", \"nsga3\"]\n",
    "\n",
    "# Mapping from environment key to Chinese name\n",
    "env_map = {\n",
    "    \"merge\": \"MERGE\",\n",
    "    \"stop\": \"STOP\",\n",
    "    \"right\": \"NARROW\"\n",
    "}\n",
    "\n",
    "# Feature name mapping\n",
    "feature_names = {\n",
    "    0: \"Acceleration\",\n",
    "    1: \"Headway\",\n",
    "    2: \"Speed\"\n",
    "}\n",
    "\n",
    "# Indices for car and bus features\n",
    "car_indices = [0, 1, 2]  # Car: Acceleration, Headway, Speed\n",
    "bus_indices = [3, 4, 5]  # Bus: Acceleration, Headway, Speed\n",
    "\n",
    "for env in environments:\n",
    "    for alg in algorithms:\n",
    "        try:\n",
    "            with open(f'../output/data_cache/{env}_{alg}.pkl', 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "                F = res.F\n",
    "\n",
    "                # Find ideal points for car and bus\n",
    "                ideal_point_index_car = np.argmin(np.sum(F[:, car_indices], axis=1))\n",
    "                ideal_point_car = F[ideal_point_index_car, car_indices]\n",
    "                \n",
    "                ideal_point_index_bus = np.argmin(np.sum(F[:, bus_indices], axis=1))\n",
    "                ideal_point_bus = F[ideal_point_index_bus, bus_indices]\n",
    "\n",
    "                fig = plt.figure(figsize=(20, 5.5))\n",
    "                \n",
    "                env_en = env_map.get(env, env.upper())\n",
    "                \n",
    "                # 3D scatter plot for Pareto front\n",
    "                ax_3d = fig.add_subplot(141, projection='3d')\n",
    "                ax_3d.set_title(f'{env_en} {alg.upper()} Pareto Front')\n",
    "                ax_3d.set_xlabel('Acceleration', labelpad=5, rotation=-10)\n",
    "                ax_3d.set_ylabel('Headway', labelpad=5, rotation=50)\n",
    "                ax_3d.set_zlabel('Speed', labelpad=5, rotation=90)\n",
    "\n",
    "                # Car data\n",
    "                ax_3d.scatter(F[:, car_indices[0]], F[:, car_indices[1]], F[:, car_indices[2]], \n",
    "                             s=30, facecolors='none', edgecolors='blue', label='Car')\n",
    "\n",
    "                # Bus data\n",
    "                ax_3d.scatter(F[:, bus_indices[0]], F[:, bus_indices[1]], F[:, bus_indices[2]], \n",
    "                             s=30, facecolors='none', edgecolors='green', label='Bus')\n",
    "\n",
    "                # Mark ideal points for car and bus\n",
    "                ax_3d.scatter(ideal_point_car[0], ideal_point_car[1], ideal_point_car[2], \n",
    "                             s=100, c='red', marker='x', label='Ideal Point (Car)', facecolors='white')\n",
    "                ax_3d.scatter(ideal_point_bus[0], ideal_point_bus[1], ideal_point_bus[2], \n",
    "                             s=100, c='red', marker='o', label='Ideal Point (Bus)', facecolors='white')\n",
    "                \n",
    "                # 2D feature index pairs: (Acceleration, Headway), (Acceleration, Speed), (Headway, Speed)\n",
    "                pairs = [(0, 1), (0, 2), (1, 2)]\n",
    "\n",
    "                for i, (x_idx, y_idx) in enumerate(pairs):\n",
    "                    ax = fig.add_subplot(1, 4, i + 2)\n",
    "                    ax.set_title(f'{env_en} {alg.upper()}: {feature_names[x_idx]} vs {feature_names[y_idx]}')\n",
    "                    ax.set_xlabel(f'{feature_names[x_idx]} KL Divergence')\n",
    "                    ax.set_ylabel(f'{feature_names[y_idx]} KL Divergence')\n",
    "\n",
    "                    # Car data\n",
    "                    ax.scatter(F[:, car_indices[x_idx]], F[:, car_indices[y_idx]], \n",
    "                              s=40, facecolors='none', edgecolors='blue', label='Car', alpha=0.6)\n",
    "\n",
    "                    # Bus data\n",
    "                    ax.scatter(F[:, bus_indices[x_idx]], F[:, bus_indices[y_idx]], \n",
    "                              s=40, facecolors='none', edgecolors='green', label='Bus', alpha=0.6)\n",
    "                    ax.grid(visible=True, linestyle='--', alpha=0.5)\n",
    "\n",
    "                    # Mark ideal points for car and bus\n",
    "                    ax.scatter(ideal_point_car[x_idx], ideal_point_car[y_idx], \n",
    "                              s=100, c='red', marker='x', label='Ideal Point (Car)')\n",
    "                    ax.scatter(ideal_point_bus[x_idx], ideal_point_bus[y_idx], \n",
    "                              s=100, c='red', marker='o', label='Ideal Point (Bus)')\n",
    "                    \n",
    "                    # Annotate ideal points\n",
    "                    ax.annotate(f'({ideal_point_car[x_idx]:.3f}, {ideal_point_car[y_idx]:.3f})',\n",
    "                               xy=(ideal_point_car[x_idx], ideal_point_car[y_idx]),\n",
    "                               xytext=(10, 60), textcoords='offset points',\n",
    "                               arrowprops=dict(arrowstyle=\"->\", color='black', linestyle='--', lw=2),\n",
    "                               color='black', fontweight='bold')\n",
    "                    \n",
    "                    ax.annotate(f'({ideal_point_bus[x_idx]:.3f}, {ideal_point_bus[y_idx]:.3f})',\n",
    "                               xy=(ideal_point_bus[x_idx], ideal_point_bus[y_idx]),\n",
    "                               xytext=(90, 30), textcoords='offset points',\n",
    "                               arrowprops=dict(arrowstyle=\"->\", color='black', linestyle='--', lw=1),\n",
    "                               color='black')\n",
    "                    \n",
    "                    # Show legend only in the first subplot to avoid repetition\n",
    "                    ax.legend(fontsize=13, loc=\"upper right\")\n",
    "\n",
    "                plt.tight_layout(pad=2.5)\n",
    "                plt.savefig(f'../output/plot/scatter/{env}_{alg}_pareto_front.pdf', dpi=300)\n",
    "                plt.show()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pareto Front Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi_object_optimization import MooSUMOProblem, SinSUMOProblem\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List of environments and algorithms\n",
    "environments = [\"merge\", \"stop\", \"right\"]\n",
    "algorithms = [\"age2\", \"nsga3\"]\n",
    "\n",
    "# Mapping for environment names (Chinese to English)\n",
    "env_map = {\n",
    "    \"merge\": \"MERGE\",\n",
    "    \"stop\": \"STOP\",\n",
    "    \"right\": \"NARROW\"\n",
    "}\n",
    "\n",
    "# Feature names mapping (Chinese to English)\n",
    "feature_names = {\n",
    "    0: \"Acceleration\",\n",
    "    1: \"Headway\",\n",
    "    2: \"Speed\"\n",
    "}\n",
    "\n",
    "# Indices for car and bus features\n",
    "car_indices = [0, 1, 2]  # Car: Acceleration, Headway, Speed\n",
    "bus_indices = [3, 4, 5]  # Bus: Acceleration, Headway, Speed\n",
    "\n",
    "results = []\n",
    "\n",
    "# Iterate over all environment and algorithm combinations\n",
    "for env in environments:\n",
    "    for alg in algorithms:\n",
    "        try:\n",
    "            with open(f'../output/data_cache/{env}_{alg}.pkl', 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "                F = res.F\n",
    "\n",
    "                # Find ideal points for car and bus (minimize sum of objectives)\n",
    "                ideal_point_index_car = np.argmin(np.sum(F[:, car_indices], axis=1))\n",
    "                ideal_point_car = F[ideal_point_index_car, car_indices]\n",
    "                \n",
    "                ideal_point_index_bus = np.argmin(np.sum(F[:, bus_indices], axis=1))\n",
    "                ideal_point_bus = F[ideal_point_index_bus, bus_indices]\n",
    "                \n",
    "                pareto_points_count = F.shape[0]\n",
    "                \n",
    "                # Compute statistics for each feature\n",
    "                car_stats = {\n",
    "                    \"Acceleration\": {\n",
    "                        \"min\": np.min(F[:, car_indices[0]]),\n",
    "                        \"max\": np.max(F[:, car_indices[0]]),\n",
    "                        \"mean\": np.mean(F[:, car_indices[0]]),\n",
    "                        \"ideal\": ideal_point_car[0]\n",
    "                    },\n",
    "                    \"Headway\": {\n",
    "                        \"min\": np.min(F[:, car_indices[1]]),\n",
    "                        \"max\": np.max(F[:, car_indices[1]]),\n",
    "                        \"mean\": np.mean(F[:, car_indices[1]]),\n",
    "                        \"ideal\": ideal_point_car[1]\n",
    "                    },\n",
    "                    \"Speed\": {\n",
    "                        \"min\": np.min(F[:, car_indices[2]]),\n",
    "                        \"max\": np.max(F[:, car_indices[2]]),\n",
    "                        \"mean\": np.mean(F[:, car_indices[2]]),\n",
    "                        \"ideal\": ideal_point_car[2]\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                bus_stats = {\n",
    "                    \"Acceleration\": {\n",
    "                        \"min\": np.min(F[:, bus_indices[0]]),\n",
    "                        \"max\": np.max(F[:, bus_indices[0]]),\n",
    "                        \"mean\": np.mean(F[:, bus_indices[0]]),\n",
    "                        \"ideal\": ideal_point_bus[0]\n",
    "                    },\n",
    "                    \"Headway\": {\n",
    "                        \"min\": np.min(F[:, bus_indices[1]]),\n",
    "                        \"max\": np.max(F[:, bus_indices[1]]),\n",
    "                        \"mean\": np.mean(F[:, bus_indices[1]]),\n",
    "                        \"ideal\": ideal_point_bus[1]\n",
    "                    },\n",
    "                    \"Speed\": {\n",
    "                        \"min\": np.min(F[:, bus_indices[2]]),\n",
    "                        \"max\": np.max(F[:, bus_indices[2]]),\n",
    "                        \"mean\": np.mean(F[:, bus_indices[2]]),\n",
    "                        \"ideal\": ideal_point_bus[2]\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                # Store results\n",
    "                results.append({\n",
    "                    \"Environment\": env_map[env],\n",
    "                    \"Algorithm\": alg.upper(),\n",
    "                    \"Pareto Point Count\": pareto_points_count,\n",
    "                    \"Car Stats\": car_stats,\n",
    "                    \"Bus Stats\": bus_stats\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {env}_{alg}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Generate LaTeX table for ideal points\n",
    "def generate_latex_table(results):\n",
    "    latex = \"\"\"\n",
    "\\\\begin{table}[htbp]\n",
    "  \\\\centering\n",
    "  \\\\caption{Pareto Front Statistics for Multi-objective Optimization Algorithms in Different Scenarios}\n",
    "  \\\\label{tab:pareto_front_stats}\n",
    "  \\\\begin{tabular}{ccccccccc}\n",
    "    \\\\toprule\n",
    "    \\\\multirow{2}{*}{Scenario} & \\\\multirow{2}{*}{Algorithm} & \\\\multirow{2}{*}{Pareto Points} & \\\\multicolumn{3}{c}{Car Ideal Point} & \\\\multicolumn{3}{c}{Bus Ideal Point} \\\\\\\\\n",
    "    \\\\cmidrule(lr){4-6} \\\\cmidrule(lr){7-9}\n",
    "    & & & Acceleration & Headway & Speed & Acceleration & Headway & Speed \\\\\\\\\n",
    "    \\\\midrule\n",
    "\"\"\"\n",
    "    for res in results:\n",
    "        latex += f\"    {res['Environment']} & {res['Algorithm']} & {res['Pareto Point Count']} & \"\n",
    "        latex += f\"{res['Car Stats']['Acceleration']['ideal']:.3f} & {res['Car Stats']['Headway']['ideal']:.3f} & {res['Car Stats']['Speed']['ideal']:.3f} & \"\n",
    "        latex += f\"{res['Bus Stats']['Acceleration']['ideal']:.3f} & {res['Bus Stats']['Headway']['ideal']:.3f} & {res['Bus Stats']['Speed']['ideal']:.3f} \\\\\\\\\\n\"\n",
    "    latex += \"\"\"    \\\\bottomrule\n",
    "  \\\\end{tabular}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "    return latex\n",
    "\n",
    "# Generate LaTeX table for value ranges\n",
    "def generate_range_table(results):\n",
    "    latex = \"\"\"\n",
    "\\\\begin{table}[htbp]\n",
    "  \\\\centering\n",
    "  \\\\caption{Pareto Front Feature Ranges for Multi-objective Optimization Algorithms in Different Scenarios}\n",
    "  \\\\label{tab:pareto_front_ranges}\n",
    "  \\\\begin{tabular}{cccccccc}\n",
    "    \\\\toprule\n",
    "    \\\\multirow{2}{*}{Scenario} & \\\\multirow{2}{*}{Algorithm} & \\\\multicolumn{3}{c}{Car Feature Range (min-max)} & \\\\multicolumn{3}{c}{Bus Feature Range (min-max)} \\\\\\\\\n",
    "    \\\\cmidrule(lr){3-5} \\\\cmidrule(lr){6-8}\n",
    "    & & Acceleration & Headway & Speed & Acceleration & Headway & Speed \\\\\\\\\n",
    "    \\\\midrule\n",
    "\"\"\"\n",
    "    for res in results:\n",
    "        latex += f\"    {res['Environment']} & {res['Algorithm']} & \"\n",
    "        latex += f\"{res['Car Stats']['Acceleration']['min']:.3f}-{res['Car Stats']['Acceleration']['max']:.3f} & \"\n",
    "        latex += f\"{res['Car Stats']['Headway']['min']:.3f}-{res['Car Stats']['Headway']['max']:.3f} & \"\n",
    "        latex += f\"{res['Car Stats']['Speed']['min']:.3f}-{res['Car Stats']['Speed']['max']:.3f} & \"\n",
    "        latex += f\"{res['Bus Stats']['Acceleration']['min']:.3f}-{res['Bus Stats']['Acceleration']['max']:.3f} & \"\n",
    "        latex += f\"{res['Bus Stats']['Headway']['min']:.3f}-{res['Bus Stats']['Headway']['max']:.3f} & \"\n",
    "        latex += f\"{res['Bus Stats']['Speed']['min']:.3f}-{res['Bus Stats']['Speed']['max']:.3f} \\\\\\\\\\n\"\n",
    "    latex += \"\"\"    \\\\bottomrule\n",
    "  \\\\end{tabular}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "    return latex\n",
    "\n",
    "# Generate LaTeX table for means\n",
    "def generate_mean_table(results):\n",
    "    latex = \"\"\"\n",
    "\\\\begin{table}[htbp]\n",
    "  \\\\centering\n",
    "  \\\\caption{Pareto Front Feature Means for Multi-objective Optimization Algorithms in Different Scenarios}\n",
    "  \\\\label{tab:pareto_front_means}\n",
    "  \\\\begin{tabular}{cccccccc}\n",
    "    \\\\toprule\n",
    "    \\\\multirow{2}{*}{Scenario} & \\\\multirow{2}{*}{Algorithm} & \\\\multicolumn{3}{c}{Car Feature Mean} & \\\\multicolumn{3}{c}{Bus Feature Mean} \\\\\\\\\n",
    "    \\\\cmidrule(lr){3-5} \\\\cmidrule(lr){6-8}\n",
    "    & & Acceleration & Headway & Speed & Acceleration & Headway & Speed \\\\\\\\\n",
    "    \\\\midrule\n",
    "\"\"\"\n",
    "    for res in results:\n",
    "        latex += f\"    {res['Environment']} & {res['Algorithm']} & \"\n",
    "        latex += f\"{res['Car Stats']['Acceleration']['mean']:.3f} & {res['Car Stats']['Headway']['mean']:.3f} & {res['Car Stats']['Speed']['mean']:.3f} & \"\n",
    "        latex += f\"{res['Bus Stats']['Acceleration']['mean']:.3f} & {res['Bus Stats']['Headway']['mean']:.3f} & {res['Bus Stats']['Speed']['mean']:.3f} \\\\\\\\\\n\"\n",
    "    latex += \"\"\"    \\\\bottomrule\n",
    "  \\\\end{tabular}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "    return latex\n",
    "\n",
    "# Generate comprehensive LaTeX table\n",
    "def generate_comprehensive_table(results):\n",
    "    latex = \"\"\"\n",
    "\\\\begin{table}[htbp]\n",
    "  \\\\centering\n",
    "  \\\\caption{Comprehensive Pareto Front Statistics for Multi-objective Optimization Algorithms in Different Scenarios}\n",
    "  \\\\label{tab:pareto_front_comprehensive}\n",
    "  \\\\resizebox{\\\\textwidth}{!}{%\n",
    "  \\\\begin{tabular}{ccc|ccc|ccc|ccc|ccc}\n",
    "    \\\\toprule\n",
    "    \\\\multirow{3}{*}{Scenario} & \\\\multirow{3}{*}{Algorithm} & \\\\multirow{3}{*}{Pareto Points} & \n",
    "    \\\\multicolumn{6}{c|}{Car} & \\\\multicolumn{6}{c}{Bus} \\\\\\\\\n",
    "    \\\\cmidrule(lr){4-9} \\\\cmidrule(lr){10-15}\n",
    "    & & & \\\\multicolumn{3}{c|}{Feature Range (min-max)} & \\\\multicolumn{3}{c|}{Ideal Point} & \n",
    "    \\\\multicolumn{3}{c|}{Feature Range (min-max)} & \\\\multicolumn{3}{c}{Ideal Point} \\\\\\\\\n",
    "    \\\\cmidrule(lr){4-6} \\\\cmidrule(lr){7-9} \\\\cmidrule(lr){10-12} \\\\cmidrule(lr){13-15}\n",
    "    & & & Acceleration & Headway & Speed & Acceleration & Headway & Speed & Acceleration & Headway & Speed & Acceleration & Headway & Speed \\\\\\\\\n",
    "    \\\\midrule\n",
    "\"\"\"\n",
    "    for res in results:\n",
    "        latex += f\"    {res['Environment']} & {res['Algorithm']} & {res['Pareto Point Count']} & \"\n",
    "        # Car feature range\n",
    "        latex += f\"{res['Car Stats']['Acceleration']['min']:.3f}-{res['Car Stats']['Acceleration']['max']:.3f} & \"\n",
    "        latex += f\"{res['Car Stats']['Headway']['min']:.3f}-{res['Car Stats']['Headway']['max']:.3f} & \"\n",
    "        latex += f\"{res['Car Stats']['Speed']['min']:.3f}-{res['Car Stats']['Speed']['max']:.3f} & \"\n",
    "        # Car ideal point\n",
    "        latex += f\"{res['Car Stats']['Acceleration']['ideal']:.3f} & {res['Car Stats']['Headway']['ideal']:.3f} & {res['Car Stats']['Speed']['ideal']:.3f} & \"\n",
    "        # Bus feature range\n",
    "        latex += f\"{res['Bus Stats']['Acceleration']['min']:.3f}-{res['Bus Stats']['Acceleration']['max']:.3f} & \"\n",
    "        latex += f\"{res['Bus Stats']['Headway']['min']:.3f}-{res['Bus Stats']['Headway']['max']:.3f} & \"\n",
    "        latex += f\"{res['Bus Stats']['Speed']['min']:.3f}-{res['Bus Stats']['Speed']['max']:.3f} & \"\n",
    "        # Bus ideal point\n",
    "        latex += f\"{res['Bus Stats']['Acceleration']['ideal']:.3f} & {res['Bus Stats']['Headway']['ideal']:.3f} & {res['Bus Stats']['Speed']['ideal']:.3f} \\\\\\\\\\n\"\n",
    "    latex += \"\"\"    \\\\bottomrule\n",
    "  \\\\end{tabular}%\n",
    "  }\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "    return latex\n",
    "\n",
    "# Output LaTeX tables\n",
    "ideal_point_table = generate_latex_table(results)\n",
    "range_table = generate_range_table(results)\n",
    "mean_table = generate_mean_table(results)\n",
    "comprehensive_table = generate_comprehensive_table(results)\n",
    "\n",
    "print(\"\\nIdeal Point Table:\")\n",
    "print(ideal_point_table)\n",
    "\n",
    "# Uncomment below to print other tables\n",
    "# print(\"\\nFeature Range Table:\")\n",
    "# print(range_table)\n",
    "# print(\"\\nFeature Mean Table:\")\n",
    "# print(mean_table)\n",
    "# print(\"\\nComprehensive Table:\")\n",
    "# print(comprehensive_table)\n",
    "\n",
    "# Uncomment below to save all tables to a file\n",
    "# with open(\"pareto_front_tables.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(\"% Ideal Point Table\\n\")\n",
    "#     f.write(ideal_point_table)\n",
    "#     f.write(\"\\n\\n% Feature Range Table\\n\")\n",
    "#     f.write(range_table)\n",
    "#     f.write(\"\\n\\n% Feature Mean Table\\n\")\n",
    "#     f.write(mean_table)\n",
    "#     f.write(\"\\n\\n% Comprehensive Table\\n\")\n",
    "#     f.write(comprehensive_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
